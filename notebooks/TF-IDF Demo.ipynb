{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency - Inverse Data Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE</b>: This project is taken from \"How to process textual data using TF-IDF in Python\" by user DroidHead. Check out the blog post in [medium.freecodecamp.org](https://medium.freecodecamp.org/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3) for better explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will compute for term frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(word_dict, bow):\n",
    "    tf_dict = {}\n",
    "    bow_count = len(bow)\n",
    "    for word, count in word_dict.items():\n",
    "        tf_dict[word] = count / float(bow_count)\n",
    "    return tf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will compute for the rarity of words given a list of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(doc_list):\n",
    "    import math\n",
    "    idf_dict = {}\n",
    "    N = len(doc_list)\n",
    "    \n",
    "    idf_dict = dict.fromkeys(doc_list[0].keys(), 0)\n",
    "    for doc in doc_list:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                if word in idf_dict:\n",
    "                    idf_dict[word] += 1\n",
    "                else:\n",
    "                    idf_dict[word] = 0\n",
    "                \n",
    "    for word, val in idf_dict.items():\n",
    "        try:\n",
    "            idf_dict[word] = math.log10(N / float(val))\n",
    "        except ZeroDivisionError:\n",
    "            idf_dict[word] = None\n",
    "        \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute for the TFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_idf(tf_bow, idfs):\n",
    "    tf_idf = {}\n",
    "    for word, val in tf_bow.items():\n",
    "        if word in idfs and idfs[word] is not None:\n",
    "            tf_idf[word] = val * idfs[word]\n",
    "        else:\n",
    "            tf_idf[word] = 0\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class str(str):\n",
    "    def preprocess(self, accumulator=[]):\n",
    "        import re\n",
    "        self = re.sub(r'[^\\w\\s]','',self)\n",
    "        parsed_doc = self.lower().split(\" \")\n",
    "        accumulator['data'] = set(accumulator['data']).union(set(parsed_doc))\n",
    "        doc_dict = dict.fromkeys(parsed_doc, 0)\n",
    "        for word in parsed_doc:\n",
    "            doc_dict[word] += 1\n",
    "        return (parsed_doc, doc_dict)\n",
    "\n",
    "word_set = { 'data': [] }\n",
    "doc_a = str(\"The unicorns and cats are majestic animals that should be taken care of and loved.\")\n",
    "(doc_a_set, doc_a_dict) = doc_a.preprocess(word_set)\n",
    "\n",
    "doc_b = str(\"Gorgeous are those lovely unicorns that makes sure we are safe when we sleep.\")\n",
    "(doc_b_set, doc_b_dict) = doc_b.preprocess(word_set)\n",
    "\n",
    "doc_c = str(\"Hoy! Bantay! Anong kinakagat mo nanaman diyan!?\")\n",
    "(doc_c_set, doc_c_dict) = doc_c.preprocess(word_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak into documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Document: {}\\n\\n Dict: {}\\n\\n\".format(doc_a, doc_a_dict))\n",
    "print(\"Document: {}\\n\\n Dict: {}\\n\\n\".format(doc_b, doc_b_dict))\n",
    "print(\"Document: {}\\n\\n Dict: {}\\n\\n\".format(doc_c, doc_c_dict))\n",
    "print(word_set['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(pd.DataFrame([doc_a_dict, doc_b_dict, doc_c_dict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute for tf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_a_tf = compute_tf(doc_a_dict, doc_a)\n",
    "doc_b_tf = compute_tf(doc_b_dict, doc_b)\n",
    "doc_c_tf = compute_tf(doc_c_dict, doc_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak into the term frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Document A: {}\".format(doc_a_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute for idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = compute_idf([doc_a_dict, doc_b_dict, doc_c_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak into idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IDF for Document A, B, and C: {}\".format(idfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute for word similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_a_tfidf = compute_tf_idf(doc_a_tf, idfs)\n",
    "doc_b_tfidf = compute_tf_idf(doc_b_tf, idfs)\n",
    "doc_c_tfidf = compute_tf_idf(doc_c_tf, idfs)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(pd.DataFrame([doc_a_tfidf, doc_b_tfidf, doc_c_tfidf]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topic_modeling_demo",
   "language": "python",
   "name": "topic_modeling_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
